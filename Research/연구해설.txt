발표 슬라이드: https://github.com/cequala/Data-Analysis-Projects/blob/main/Research/A_Comparative_Study_on_Bayesian_SVDD_Models.pdf

- See the bottom for the Eng. version.
- 이 텍스트는 다운받으면 편하게 볼 수 있습니다. Download the file to read comfortably.
- 보다 세부적인 내용은 위 링크의 슬라이드 참고바랍니다. For a detailed explanation, check the presentation slide link at the most above

[연구 개요]
Support Vector Data Description(이하 SVDD) (Tax and Duin, 2004)과, 그에 베이지안을 적용한 3가지 방법론들을 비교 연구하였습니다. SVDD는 Support Vector Machine(이하 SVM)을 개조하여 이상치 탐지에 활용할 수 있는 알고리즘입니다. 데이터를 보다 높은 차원의 공간, 즉 커널 공간에서 분류한다는 아이디어는 SVM과 같으나 SVDD는 불균형 데이터에 특화된 것이 차이입니다. 불균형 데이터란 클래스마다의 크기의 차이가 극심한 데이터로, 이진 불균형 데이터의 예시로 제조업에서의 불량품 데이터를 들 수 있습니다. 이러한 데이터에 대해 SVDD는 커널 공간에서 정상 클래스를 구 형태로 감싸는 경계면을 만들어 새로운 데이터의 정상 여부를 판단합니다.

여기서 경계면을 어떻게 구하느냐에 따라 비교대상 방법론들의 차이가 드러납니다. SVDD에서는 최적화 식을 통해 얻어낸 서포트 벡터가 구를 결정합니다. 한편  Bayesian Data Description(이하 BDD) (Ghasemi et al, 2012)에서는 베이지안 관점으로 구의 중심을 구성하는 모수 알파(alpha)에 사전 분포를 부여합니다. 알파는 구의 중심 수식에서 가중치처럼 사용돼 0과 1 사이 값을 가집니다. 동시에 다수 데이터가 많이 몰린 곳을 구의 중심으로 두는 것이 합리적이므로, 알파가 정규분포를 사전분포로써 따르게 합니다. 그런데 정규분포를 따르는 확률변수가 가질 수 있는 값은 실수 전체 범위라서, 이는 앞서 말한 0과 1 사이의 범위와 상충합니다. 이런 설정에서는 사후분포 추정의 안정성을 확보할 수 없습니다.

위와 같은 문제를 해결하기 위해 Bayesian SVDD(이하 BSVDD) (오정민, 2023)에서는 알파를 또다른 모수인 베타(beta)의 함수로 표현합니다. 알파를 베타의 소프트맥스 함수로 표현하여 범위 상충 문제가 해결됩니다. BSVDD는 BDD가 알파에 사전분포를 부여한 것과 같은 논리로 베타에 정규분포를 부여합니다. 그렇게 계산된 사후분포는 잘 알려진 분포가 아니므로, MCMC를 적용하여 사후분포로부터 표본추출을 통해 경험적 분포를 만듭니다. 이렇게 만든 분포로 구의 중심 분포를 만들 수 있으며, 이를 통해 커널 공간에서 구의 중심과 새로운 데이터 하나(이하 z)와의 거리 분포를 만들 수 있게 됩니다. 이 분포 위에, 교차타당도 검증(Cross Validation)을 통해 정한 특정 역치(이하 D)를 세워서, 분포의 50% 이상이 D의 우측에 위치하면 z를 이상치로 판단하게 됩니다.

지금까지의 방법론들이 정상치 데이터만을 이용해 구를 형성합니다. 이상치 데이터까지 구 형성에 활용할 수 있다면 성능이 더 좋은 경계면을 만들 수 있을 것입니다. 이런 아이디어를 BSVDD에 적용한 것이 BSVDD-A(BSVDD with Anomaly class) (배희진, 2024) 입니다. 세부적인 전개가 BSVDD와 유사하여 설명은 생략합니다.

모수의 변동이 큰 데이터에 대해서는 모수가 고정되지 않음을 전제하는 베이지안이 적용된 세 가지 방법론이 SVDD보다 우수한 예측성능(F1-score)을 보입니다. 그리고 같은 데이터에서 BDD보다 올바르게 베이지안을 적용한 BSVDD와 BSVDD-A는 BDD에 비해 약 8% 더 나은 성능을 보입니다.

[Research Overview]
This research compares Support Vector Data Description (SVDD) (Tax and Duin, 2004) with three methodologies that apply Bayesian approaches. SVDD is an algorithm that modifies the Support Vector Machine (SVM) for anomaly detection. While both share the idea of classifying data in a high-dimensional space (a.k.a kernel space), SVDD specializes in imbalanced data. Imbalanced data refers to datasets where class sizes differ dramatically. For such data, SVDD creates a spherical boundary in the kernel space around the normal class to determine if a new data point is normal.

The differences between the compared methodologies lie in how they determine this boundary. In SVDD, support vectors obtained through optimization define the sphere. Meanwhile, Bayesian Data Description (BDD) (Ghasemi et al, 2012) applies a Bayesian perspective by assigning a prior distribution to the parameter alpha (α), which acts as a weight in the equation of the sphere's center and has values between 0 and 1. Since it's reasonable to place the sphere's center where most major-class data points cluster, alpha is given a normal distribution as a prior. However, this creates a conflict because normal distributions can take any real value, not just between 0 and 1, making posterior distribution estimation unstable.

To resolve this issue, Bayesian SVDD (BSVDD) (Oh Jeongmin, 2023) expresses alpha as a function of another parameter, beta (β). By representing alpha as a softmax function of beta, the range conflict problem is solved. BSVDD applies a normal distribution to beta, following the same logic as assigning BDD's prior distribution to alpha. Since the resulting posterior distribution is not well-known, MCMC is applied to create an empirical distribution through sampling. This allows for creating a distribution of the sphere's center, which enables measuring the distance distribution between the center and a new data point (z) in kernel space. By establishing a specific threshold (D) through cross-validation, 'z' is classified as an anomaly if more than 50% of the distribution lies to the right of 'D.'

The methodologies discussed so far only use normal data to form the sphere. BSVDD-A (BSVDD with Anomaly class) (Bae Heejin, 2024) applies the idea that incorporating anomaly data could create a better boundary. The detailed development is similar to BSVDD and is omitted here.

For data with large parameter variations, the three Bayesian methodologies (BDD, BSVDD, BSVDD-A) that assume parameters are not fixed show superior predictive performance (F1-score) compared to SVDD. Additionally, BSVDD and BSVDD-A, which correctly apply Bayesian methods, demonstrate approximately 8% better performance than BDD on the same data.
